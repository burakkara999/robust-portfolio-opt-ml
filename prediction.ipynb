{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "48d5911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "from asset_data_module import read_close_prices_all_merged\n",
    "from features import make_feature_windows\n",
    "tf.keras.utils.set_random_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "e1d2ad77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((981, 40), 430)"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markets = ['dow30', 'commodities', 'bonds']\n",
    "# markets = ['dow30']\n",
    "# markets = ['commodities']\n",
    "# markets = ['bonds']\n",
    "start_date, end_date = \"2022-01-01\", \"2025-11-28\"\n",
    "# start_date, end_date = \"2024-06-01\", \"2025-11-28\"\n",
    "\n",
    "_, close_df = read_close_prices_all_merged(markets, after_date=start_date)\n",
    "close_df = close_df.loc[:end_date]\n",
    "\n",
    "rolling = make_feature_windows(\n",
    "    close_prices=close_df,\n",
    "    lookback=60,\n",
    "    horizon=1,\n",
    "    days_per_week=2\n",
    ")\n",
    "close_df.shape, len(rolling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "22a499ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dow30:AAPL</th>\n",
       "      <th>dow30:AMGN</th>\n",
       "      <th>dow30:AXP</th>\n",
       "      <th>dow30:BA</th>\n",
       "      <th>dow30:CAT</th>\n",
       "      <th>dow30:CRM</th>\n",
       "      <th>dow30:CSCO</th>\n",
       "      <th>dow30:CVX</th>\n",
       "      <th>dow30:DIS</th>\n",
       "      <th>dow30:DOW</th>\n",
       "      <th>...</th>\n",
       "      <th>commodities:GC=F</th>\n",
       "      <th>commodities:HG=F</th>\n",
       "      <th>commodities:SI=F</th>\n",
       "      <th>bonds:EMB</th>\n",
       "      <th>bonds:HYG</th>\n",
       "      <th>bonds:IEF</th>\n",
       "      <th>bonds:LQD</th>\n",
       "      <th>bonds:SHY</th>\n",
       "      <th>bonds:TIP</th>\n",
       "      <th>bonds:TLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.039733</td>\n",
       "      <td>-0.006861</td>\n",
       "      <td>0.020885</td>\n",
       "      <td>0.024756</td>\n",
       "      <td>0.059772</td>\n",
       "      <td>-0.115169</td>\n",
       "      <td>-0.040796</td>\n",
       "      <td>0.024517</td>\n",
       "      <td>-0.010066</td>\n",
       "      <td>0.025691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013907</td>\n",
       "      <td>-0.002268</td>\n",
       "      <td>0.015673</td>\n",
       "      <td>-0.010146</td>\n",
       "      <td>-0.010286</td>\n",
       "      <td>-0.004751</td>\n",
       "      <td>-0.005046</td>\n",
       "      <td>-0.000702</td>\n",
       "      <td>-0.011982</td>\n",
       "      <td>-0.009609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.015846</td>\n",
       "      <td>0.009504</td>\n",
       "      <td>0.017646</td>\n",
       "      <td>0.011340</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>0.022731</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.012772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015242</td>\n",
       "      <td>-0.000341</td>\n",
       "      <td>-0.033202</td>\n",
       "      <td>-0.002904</td>\n",
       "      <td>-0.002443</td>\n",
       "      <td>-0.005749</td>\n",
       "      <td>-0.005612</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>-0.005530</td>\n",
       "      <td>-0.004629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016761</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>-0.019094</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>0.020082</td>\n",
       "      <td>0.023242</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011948</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>0.018231</td>\n",
       "      <td>-0.001314</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>0.008205</td>\n",
       "      <td>0.009097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.016645</td>\n",
       "      <td>-0.006606</td>\n",
       "      <td>-0.011988</td>\n",
       "      <td>0.035828</td>\n",
       "      <td>0.031550</td>\n",
       "      <td>-0.026799</td>\n",
       "      <td>-0.014047</td>\n",
       "      <td>-0.009185</td>\n",
       "      <td>-0.015639</td>\n",
       "      <td>0.012760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.025352</td>\n",
       "      <td>0.015187</td>\n",
       "      <td>-0.005464</td>\n",
       "      <td>-0.001971</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>-0.006226</td>\n",
       "      <td>0.005003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.013977</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>-0.041955</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.012564</td>\n",
       "      <td>-0.011305</td>\n",
       "      <td>-0.029203</td>\n",
       "      <td>0.020143</td>\n",
       "      <td>-0.020605</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004899</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>-0.018111</td>\n",
       "      <td>-0.005819</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.018433</td>\n",
       "      <td>-0.002818</td>\n",
       "      <td>-0.009293</td>\n",
       "      <td>-0.029399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dow30:AAPL  dow30:AMGN  dow30:AXP  dow30:BA  dow30:CAT  dow30:CRM  \\\n",
       "0   -0.039733   -0.006861   0.020885  0.024756   0.059772  -0.115169   \n",
       "1   -0.015846    0.009504   0.017646  0.011340   0.020003   0.002807   \n",
       "2    0.016761    0.022147   0.005718  0.002410  -0.019094   0.028200   \n",
       "3   -0.016645   -0.006606  -0.011988  0.035828   0.031550  -0.026799   \n",
       "4   -0.013977    0.012826  -0.041955  0.004945   0.012564  -0.011305   \n",
       "\n",
       "   dow30:CSCO  dow30:CVX  dow30:DIS  dow30:DOW  ...  commodities:GC=F  \\\n",
       "0   -0.040796   0.024517  -0.010066   0.025691  ...          0.013907   \n",
       "1    0.014002   0.022731   0.016868   0.012772  ...         -0.015242   \n",
       "2    0.020082   0.023242   0.000380   0.001353  ...          0.011948   \n",
       "3   -0.014047  -0.009185  -0.015639   0.012760  ...          0.001429   \n",
       "4   -0.029203   0.020143  -0.020605   0.004328  ...         -0.004899   \n",
       "\n",
       "   commodities:HG=F  commodities:SI=F  bonds:EMB  bonds:HYG  bonds:IEF  \\\n",
       "0         -0.002268          0.015673  -0.010146  -0.010286  -0.004751   \n",
       "1         -0.000341         -0.033202  -0.002904  -0.002443  -0.005749   \n",
       "2          0.003967          0.018231  -0.001314   0.005459   0.002127   \n",
       "3          0.025352          0.015187  -0.005464  -0.001971   0.003358   \n",
       "4         -0.035469          0.014236  -0.018111  -0.005819  -0.014483   \n",
       "\n",
       "   bonds:LQD  bonds:SHY  bonds:TIP  bonds:TLT  \n",
       "0  -0.005046  -0.000702  -0.011982  -0.009609  \n",
       "1  -0.005612  -0.001055  -0.005530  -0.004629  \n",
       "2   0.002079  -0.000235   0.008205   0.009097  \n",
       "3   0.002459   0.000117  -0.006226   0.005003  \n",
       "4  -0.018433  -0.002818  -0.009293  -0.029399  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rolling[0]['past_weekly_returns'].shape)\n",
    "rolling[0]['past_weekly_returns'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "09518f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mom_1w</th>\n",
       "      <th>mom_4w</th>\n",
       "      <th>mom_12w</th>\n",
       "      <th>vol_1w</th>\n",
       "      <th>vol_4w</th>\n",
       "      <th>sharpe_1w</th>\n",
       "      <th>sharpe_4w</th>\n",
       "      <th>vol_ratio</th>\n",
       "      <th>max_drawdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonds:EMB</th>\n",
       "      <td>-0.529241</td>\n",
       "      <td>-0.037816</td>\n",
       "      <td>-0.266307</td>\n",
       "      <td>-0.990466</td>\n",
       "      <td>-0.621157</td>\n",
       "      <td>-0.172261</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>-0.979524</td>\n",
       "      <td>0.254794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonds:HYG</th>\n",
       "      <td>-0.304409</td>\n",
       "      <td>0.087164</td>\n",
       "      <td>-0.134049</td>\n",
       "      <td>-1.223926</td>\n",
       "      <td>-1.124062</td>\n",
       "      <td>6.146437</td>\n",
       "      <td>0.527685</td>\n",
       "      <td>-1.426704</td>\n",
       "      <td>0.817271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonds:IEF</th>\n",
       "      <td>-0.735662</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>-0.198222</td>\n",
       "      <td>-0.821394</td>\n",
       "      <td>-1.335768</td>\n",
       "      <td>-0.200501</td>\n",
       "      <td>0.557177</td>\n",
       "      <td>-0.217478</td>\n",
       "      <td>0.912569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonds:LQD</th>\n",
       "      <td>-0.495279</td>\n",
       "      <td>-0.021567</td>\n",
       "      <td>-0.108969</td>\n",
       "      <td>-0.940257</td>\n",
       "      <td>-1.363098</td>\n",
       "      <td>-0.174786</td>\n",
       "      <td>0.457339</td>\n",
       "      <td>-0.683379</td>\n",
       "      <td>0.521622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonds:SHY</th>\n",
       "      <td>-0.787964</td>\n",
       "      <td>-0.235119</td>\n",
       "      <td>-0.002339</td>\n",
       "      <td>-1.178144</td>\n",
       "      <td>-2.074935</td>\n",
       "      <td>-0.193058</td>\n",
       "      <td>0.770733</td>\n",
       "      <td>-0.877848</td>\n",
       "      <td>1.867246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mom_1w    mom_4w   mom_12w    vol_1w    vol_4w  sharpe_1w  \\\n",
       "bonds:EMB -0.529241 -0.037816 -0.266307 -0.990466 -0.621157  -0.172261   \n",
       "bonds:HYG -0.304409  0.087164 -0.134049 -1.223926 -1.124062   6.146437   \n",
       "bonds:IEF -0.735662  0.021070 -0.198222 -0.821394 -1.335768  -0.200501   \n",
       "bonds:LQD -0.495279 -0.021567 -0.108969 -0.940257 -1.363098  -0.174786   \n",
       "bonds:SHY -0.787964 -0.235119 -0.002339 -1.178144 -2.074935  -0.193058   \n",
       "\n",
       "           sharpe_4w  vol_ratio  max_drawdown  \n",
       "bonds:EMB   0.004759  -0.979524      0.254794  \n",
       "bonds:HYG   0.527685  -1.426704      0.817271  \n",
       "bonds:IEF   0.557177  -0.217478      0.912569  \n",
       "bonds:LQD   0.457339  -0.683379      0.521622  \n",
       "bonds:SHY   0.770733  -0.877848      1.867246  "
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling[0]['X_feat'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "961e94f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonds:EMB   -0.007649\n",
       "bonds:HYG   -0.011056\n",
       "bonds:IEF    0.001292\n",
       "dtype: float64"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling[0]['y_ret'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "2d2947a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def panel_from_windows(windows, x_key=\"past_weekly_returns\", y_key=\"y_ret\"):\n",
    "    X_list, y_list = [], []\n",
    "    meta_rows = []\n",
    "\n",
    "    for w_idx, w in enumerate(windows):\n",
    "        if x_key == 'past_weekly_returns':\n",
    "            X_df = w[x_key].T          # assets x n_lookback (weeks) (DataFrame)\n",
    "        elif x_key == 'X_feat':\n",
    "            X_df = w[x_key]          # assets x n_features (DataFrame)\n",
    "        y_ser = w[y_key]           # assets (Series or array)\n",
    "\n",
    "        if not isinstance(y_ser, pd.Series):\n",
    "            y_ser = pd.Series(y_ser, index=X_df.index)\n",
    "\n",
    "        assets = X_df.index.intersection(y_ser.index)\n",
    "        Xw = X_df.loc[assets].to_numpy(dtype=np.float32)\n",
    "        yw = y_ser.loc[assets].to_numpy(dtype=np.float32)\n",
    "\n",
    "        mask = np.isfinite(Xw).all(axis=1) & np.isfinite(yw)\n",
    "        Xw, yw = Xw[mask], yw[mask]\n",
    "        assets_kept = assets.to_numpy()[mask]\n",
    "\n",
    "        X_list.append(Xw)\n",
    "        y_list.append(yw)\n",
    "\n",
    "        t0, t1 = w.get(\"t0\", None), w.get(\"t1\", None)\n",
    "        for a in assets_kept:\n",
    "            meta_rows.append((w_idx, a, t0, t1))\n",
    "\n",
    "    X = np.vstack(X_list) ## weeks*assets x n_lookback/n_features\n",
    "    y = np.concatenate(y_list)\n",
    "    meta = pd.DataFrame(meta_rows, columns=[\"window_idx\", \"asset\", \"t0\", \"t1\"])\n",
    "    return X, y, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "00e8a1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17200, 60),\n",
       " (17200,),\n",
       "    window_idx       asset         t0         t1\n",
       " 0           0  dow30:AAPL 2022-06-24 2022-06-28\n",
       " 1           0  dow30:AMGN 2022-06-24 2022-06-28\n",
       " 2           0   dow30:AXP 2022-06-24 2022-06-28\n",
       " 3           0    dow30:BA 2022-06-24 2022-06-28\n",
       " 4           0   dow30:CAT 2022-06-24 2022-06-28)"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_past_returns, y, meta = panel_from_windows(rolling, x_key='past_weekly_returns')\n",
    "X, y, meta = panel_from_windows(rolling, x_key='past_weekly_returns')\n",
    "# X, y, meta = panel_from_windows(rolling, x_key='X_feat')\n",
    "X.shape, y.shape, meta.head() ## len(rolling)*n_asset -- each row is a feature set -- to predict y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "4dcd561f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01450700405985117"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows = rolling  # your rolling list\n",
    "\n",
    "W = meta[\"window_idx\"].nunique()\n",
    "split_w = int(0.8 * W)\n",
    "\n",
    "train_mask = (meta[\"window_idx\"] < split_w).values\n",
    "test_mask  = (meta[\"window_idx\"] >= split_w).values\n",
    "\n",
    "X_train_raw, y_train = X[train_mask], y[train_mask]\n",
    "X_test_raw,  y_test  = X[test_mask],  y[test_mask]\n",
    "X_past_returns_test_raw = X_past_returns[test_mask]\n",
    "\n",
    "# small validation from the tail of the training windows\n",
    "val_w = max(int(0.1 * split_w), 1)\n",
    "val_start = split_w - val_w\n",
    "val_mask = ((meta[\"window_idx\"] >= val_start) & (meta[\"window_idx\"] < split_w)).values\n",
    "tr2_mask = (meta[\"window_idx\"] < val_start).values\n",
    "\n",
    "X_tr_raw, y_tr = X[tr2_mask], y[tr2_mask]\n",
    "X_va_raw, y_va = X[val_mask], y[val_mask]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_tr_raw).astype(np.float32)\n",
    "X_va = scaler.transform(X_va_raw).astype(np.float32)\n",
    "X_te = scaler.transform(X_test_raw).astype(np.float32)\n",
    "\n",
    "y_tr = y_tr.astype(np.float32)\n",
    "y_va = y_va.astype(np.float32)\n",
    "y_te = y_test.astype(np.float32)\n",
    "\n",
    "## SCALE Y\n",
    "y_mean = y_tr.mean()\n",
    "y_std  = y_tr.std() + 1e-8\n",
    "\n",
    "y_tr_s = ((y_tr - y_mean) / y_std).astype(np.float32)\n",
    "y_va_s = ((y_va - y_mean) / y_std).astype(np.float32)\n",
    "float(y_std)\n",
    "\n",
    "# X_tr = np.tanh(X_tr)\n",
    "# X_va = np.tanh(X_va)\n",
    "# X_te = np.tanh(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "c0b49e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12400, 60),\n",
       " (1360, 60),\n",
       " (3440, 60),\n",
       " (12400,),\n",
       " (1360,),\n",
       " (3440,),\n",
       " '86.0 test periods')"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_va.shape, X_te.shape, y_tr.shape, y_va.shape, y_te.shape, f\"{y_te.shape[0]/close_df.shape[1]} test periods\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "0569f5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.3971 - mae: 0.8289 - val_loss: 1.3210 - val_mae: 0.7831\n",
      "Epoch 2/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 1.2883 - mae: 0.7908 - val_loss: 1.2687 - val_mae: 0.7626\n",
      "Epoch 3/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 1.2432 - mae: 0.7714 - val_loss: 1.2331 - val_mae: 0.7474\n",
      "Epoch 4/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 1.1735 - mae: 0.7476 - val_loss: 1.2095 - val_mae: 0.7371\n",
      "Epoch 5/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 1.1514 - mae: 0.7376 - val_loss: 1.1937 - val_mae: 0.7297\n",
      "Epoch 6/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 1.1364 - mae: 0.7331 - val_loss: 1.1805 - val_mae: 0.7234\n",
      "Epoch 7/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 1.1104 - mae: 0.7230 - val_loss: 1.1716 - val_mae: 0.7186\n",
      "Epoch 8/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 1.0919 - mae: 0.7169 - val_loss: 1.1642 - val_mae: 0.7147\n",
      "Epoch 9/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 1.0783 - mae: 0.7095 - val_loss: 1.1579 - val_mae: 0.7116\n",
      "Epoch 10/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 1.0630 - mae: 0.7062 - val_loss: 1.1539 - val_mae: 0.7094\n",
      "Epoch 11/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 1.0617 - mae: 0.7024 - val_loss: 1.1502 - val_mae: 0.7075\n",
      "Epoch 12/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 1.0412 - mae: 0.6959 - val_loss: 1.1468 - val_mae: 0.7060\n",
      "Epoch 13/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 1.0457 - mae: 0.6959 - val_loss: 1.1440 - val_mae: 0.7045\n",
      "Epoch 14/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 1.0321 - mae: 0.6906 - val_loss: 1.1409 - val_mae: 0.7033\n",
      "Epoch 15/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 1.0304 - mae: 0.6909 - val_loss: 1.1388 - val_mae: 0.7023\n",
      "Epoch 16/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 1.0149 - mae: 0.6858 - val_loss: 1.1368 - val_mae: 0.7014\n",
      "Epoch 17/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 1.0085 - mae: 0.6842 - val_loss: 1.1351 - val_mae: 0.7007\n",
      "Epoch 18/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 1.0120 - mae: 0.6844 - val_loss: 1.1337 - val_mae: 0.6999\n",
      "Epoch 19/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 1.0119 - mae: 0.6831 - val_loss: 1.1323 - val_mae: 0.6992\n",
      "Epoch 20/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 1.0025 - mae: 0.6810 - val_loss: 1.1316 - val_mae: 0.6989\n",
      "Epoch 21/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 1.0013 - mae: 0.6794 - val_loss: 1.1295 - val_mae: 0.6983\n",
      "Epoch 22/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 0.9989 - mae: 0.6792 - val_loss: 1.1293 - val_mae: 0.6980\n",
      "Epoch 23/100\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 0.9976 - mae: 0.6774 - val_loss: 1.1285 - val_mae: 0.6977\n",
      "Epoch 24/100\n",
      "\u001b[1m  1/124\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6514 - mae: 0.5795"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[666]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# model = build_mlp(in_dim=X_tr.shape[1], hidden=(15, 15, 15, 15, 15, 15), dropout=0.0, lr=1e-4)\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# model = build_mlp(in_dim=X_tr.shape[1], hidden=(15, 15, 15, 15, 15, 15), dropout=0.0, lr=0.01)\u001b[39;00m\n\u001b[32m     21\u001b[39m callbacks = [\n\u001b[32m     22\u001b[39m     keras.callbacks.EarlyStopping(\n\u001b[32m     23\u001b[39m         monitor=\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m, patience=\u001b[32m100\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     24\u001b[39m     )\n\u001b[32m     25\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# X_tr, y_tr,\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m## Scaled y\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# validation_data=(X_va, y_va),\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_va_s\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m## Scaled y\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# epochs=150,\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# batch_size=256,\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OZU/CS540/projectCS540/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OZU/CS540/projectCS540/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OZU/CS540/projectCS540/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OZU/CS540/projectCS540/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OZU/CS540/projectCS540/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OZU/CS540/projectCS540/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OZU/CS540/projectCS540/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    130\u001b[39m args = args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[32m    131\u001b[39m kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m function = \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OZU/CS540/projectCS540/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OZU/CS540/projectCS540/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:239\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    229\u001b[39m lookup_func_type, lookup_func_context = (\n\u001b[32m    230\u001b[39m     function_type_utils.make_canonicalized_monomorphic_type(\n\u001b[32m    231\u001b[39m         args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    235\u001b[39m     )\n\u001b[32m    236\u001b[39m )\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m   concrete_function = \u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunction_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m      \u001b[49m\u001b[43mlookup_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_func_context\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    243\u001b[39m   concrete_function = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OZU/CS540/projectCS540/.venv/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_cache.py:47\u001b[39m, in \u001b[36mFunctionCache.lookup\u001b[39m\u001b[34m(self, function_type, context)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Looks up a function based on the context and type.\"\"\"\u001b[39;00m\n\u001b[32m     46\u001b[39m context = context \u001b[38;5;129;01mor\u001b[39;00m FunctionContext()\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_dict\u001b[49m:\n\u001b[32m     48\u001b[39m   dispatch_type = \u001b[38;5;28mself\u001b[39m._dispatch_dict[context].dispatch(function_type)\n\u001b[32m     49\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/enum.py:1267\u001b[39m, in \u001b[36mEnum.__hash__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec):\n\u001b[32m   1265\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m.\u001b[34m__format__\u001b[39m(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m), format_spec)\n\u001b[32m-> \u001b[39m\u001b[32m1267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m(\u001b[38;5;28mself\u001b[39m._name_)\n\u001b[32m   1270\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__reduce_ex__\u001b[39m(\u001b[38;5;28mself\u001b[39m, proto):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def build_mlp(in_dim, hidden=(64, 32), dropout=0.1, lr=1e-3):\n",
    "    inputs = keras.Input(shape=(in_dim,))\n",
    "    x = inputs\n",
    "    for h in hidden:\n",
    "        x = layers.Dense(h, activation=\"relu\",)(x) #kernel_regularizer=regularizers.l2(1e-4)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "    outputs = layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"mse\",\n",
    "        metrics=[keras.metrics.MeanAbsoluteError(name=\"mae\")]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_mlp(in_dim=X_tr.shape[1], hidden=(32, 16), dropout=0.1, lr=1e-4)\n",
    "# model = build_mlp(in_dim=X_tr.shape[1], hidden=(15, 15, 15, 15, 15, 15), dropout=0.0, lr=1e-4)\n",
    "# model = build_mlp(in_dim=X_tr.shape[1], hidden=(15, 15, 15, 15, 15, 15), dropout=0.0, lr=0.01)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=100, restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    # X_tr, y_tr,\n",
    "    X_tr, y_tr_s,   ## Scaled y\n",
    "    # validation_data=(X_va, y_va),\n",
    "    validation_data=(X_va, y_va_s),   ## Scaled y\n",
    "    # epochs=150,\n",
    "    epochs=100,\n",
    "    # batch_size=256,\n",
    "    batch_size=100,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def prediction_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2  = r2_score(y_true, y_pred)\n",
    "    sign_acc = (np.sign(y_true) == np.sign(y_pred)).mean()\n",
    "    corr = np.corrcoef(y_true, y_pred)[0, 1] if len(y_true) > 1 else np.nan\n",
    "    \n",
    "    return {\"MSE\": round(mse, 5), \"MAE\": round(mae, 5), \"R2\": round(r2, 5), \"SignAcc\": round(float(sign_acc), 5), \"Corr\": round(float(corr), 5)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841800ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean\n",
      "{'MSE': 0.0004, 'MAE': 0.01182, 'R2': -0.04956, 'SignAcc': 0.4939, 'Corr': -0.08761}\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "MLP\n",
      "{'MSE': 0.0004, 'MAE': 0.01197, 'R2': -0.04626, 'SignAcc': 0.49913, 'Corr': -0.00296}\n",
      "0.001889708\n"
     ]
    }
   ],
   "source": [
    "y_pred_sm = X_past_returns_test_raw.astype(np.float32).mean(axis=1)\n",
    "# X_te_raw = scaler.inverse_transform(X_te)\n",
    "# y_pred_sm = X_te_raw.mean(axis=1)\n",
    "print(\"Sample Mean\")\n",
    "print(prediction_metrics(y_te, y_pred_sm))\n",
    "\n",
    "# y_pred = model.predict(X_te, batch_size=1024).squeeze()\n",
    "## Scaled y:\n",
    "pred_s = model.predict(X_te, batch_size=1024).squeeze()\n",
    "y_pred = y_mean + y_std * pred_s\n",
    "\n",
    "print(\"MLP\")\n",
    "print(prediction_metrics(y_te, y_pred))\n",
    "\n",
    "print(y_te.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_sample_mean(test_window):\n",
    "    # past_weekly_returns: (lookback periods) x (assets)\n",
    "    return test_window[\"past_weekly_returns\"].mean(axis=0)  # pd.Series indexed by asset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35858728",
   "metadata": {},
   "source": [
    "Walk-Forward Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2307a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_eval_mlp(\n",
    "    rolling,\n",
    "    train_len=150,          # number of windows to train on each step\n",
    "    x_key=\"X_feat\",\n",
    "    y_key=\"y_ret\",\n",
    "    hidden=(64, 32),\n",
    "    dropout=0.1,\n",
    "    lr=3e-4,\n",
    "    epochs=150,\n",
    "    batch_size=256,\n",
    "    seed=42\n",
    "):\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "    all_rows = []\n",
    "    week_metrics = []\n",
    "\n",
    "    for i in range(train_len, len(rolling)):\n",
    "        train_windows = rolling[i-train_len:i]\n",
    "        test_window   = rolling[i]\n",
    "\n",
    "        # --- build train panel ---\n",
    "        X_train, y_train, meta = panel_from_windows(train_windows, x_key=x_key, y_key=y_key)\n",
    "        if X_train.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # --- scaler on TRAIN only ---\n",
    "        scaler = StandardScaler()\n",
    "        X_train_sc = scaler.fit_transform(X_train).astype(np.float32)\n",
    "\n",
    "        # --- build test cross-section ---\n",
    "        X_test_df = test_window[x_key]            # assets x features\n",
    "        y_test = test_window[y_key]\n",
    "        if not isinstance(y_test, pd.Series):\n",
    "            y_test = pd.Series(y_test, index=X_test_df.index)\n",
    "\n",
    "        assets = X_test_df.index.intersection(y_test.index).sort_values()\n",
    "        X_test = X_test_df.loc[assets].to_numpy(np.float32)\n",
    "        y_true = y_test.loc[assets].to_numpy(np.float32)\n",
    "\n",
    "        mask = np.isfinite(X_test).all(axis=1) & np.isfinite(y_true)\n",
    "        assets = assets[mask]\n",
    "        X_test = X_test[mask]\n",
    "        y_true = y_true[mask]\n",
    "\n",
    "        X_test_sc = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "        # --- train model (fresh each step) ---\n",
    "        model = build_mlp(in_dim=X_train_sc.shape[1], hidden=hidden, dropout=dropout, lr=lr)\n",
    "        es = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=15, restore_best_weights=True)\n",
    "\n",
    "        model.fit(\n",
    "            X_train_sc, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0,\n",
    "            callbacks=[es]\n",
    "        )\n",
    "\n",
    "        # --- predict ---\n",
    "        y_pred = model.predict(X_test_sc, batch_size=1024, verbose=0).squeeze()\n",
    "\n",
    "        # --- baseline: sample mean of past period returns ---\n",
    "        y_pred_sm_ser = baseline_sample_mean(test_window).loc[assets]\n",
    "        y_pred_sm = y_pred_sm_ser.to_numpy(np.float32)\n",
    "\n",
    "        # store per-asset predictions\n",
    "        for a, yt, yp, ypsm in zip(assets, y_true, y_pred, y_pred_sm):\n",
    "            all_rows.append(\n",
    "                {\"window_idx\": i, \"asset\": a, \"y\": float(yt), \"pred_mlp\": float(yp), \"pred_sm\": float(ypsm)}\n",
    "            )\n",
    "\n",
    "        # per-window metrics (cross-section)\n",
    "        m_mlp = prediction_metrics(y_true, y_pred)\n",
    "        m_sm  = prediction_metrics(y_true, y_pred_sm)\n",
    "        week_metrics.append({\"window_idx\": i, **{f\"mlp_{k}\": v for k,v in m_mlp.items()},\n",
    "                                **{f\"sm_{k}\": v for k,v in m_sm.items()}})\n",
    "\n",
    "    preds_df = pd.DataFrame(all_rows)\n",
    "    week_df  = pd.DataFrame(week_metrics)\n",
    "\n",
    "    # pooled metrics over all (window, asset) test points\n",
    "    pooled_mlp = prediction_metrics(preds_df[\"y\"], preds_df[\"pred_mlp\"])\n",
    "    pooled_sm  = prediction_metrics(preds_df[\"y\"], preds_df[\"pred_sm\"])\n",
    "\n",
    "    return preds_df, week_df, pooled_mlp, pooled_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ebbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_df, week_df, pooled_mlp, pooled_sm = walk_forward_eval_mlp(\n",
    "#     rolling=rolling,\n",
    "#     train_len=100,   # e.g., last 52 periods (with days_per_week=2 that's ~104 trading days)\n",
    "#     x_key=\"X_feat\",\n",
    "#     y_key=\"y_ret\",\n",
    "#     hidden=(16,8)\n",
    "# )\n",
    "\n",
    "# print(\"Pooled MLP:\", pooled_mlp)\n",
    "# print(\"Pooled  SM:\", pooled_sm)\n",
    "# print(\"Weekly win-rate (MAE):\", (week_df[\"mlp_MAE\"] < week_df[\"sm_MAE\"]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a76b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_export_mlp(\n",
    "    rolling,\n",
    "    markets: list[str],\n",
    "    model_name: str = \"MLP\",\n",
    "    year: int = 2025,\n",
    "    train_len: int = 200,\n",
    "    x_key: str = \"past_weekly_returns\",\n",
    "    y_key: str = \"y_ret\",\n",
    "    hidden=(32, 16),\n",
    "    dropout: float = 0.1,\n",
    "    lr: float = 3e-4,\n",
    "    epochs: int = 150,\n",
    "    batch_size: int = 256,\n",
    "    seed: int = 42,\n",
    "    out_dir: str = \"data/prediction\",\n",
    "    date_key_candidates=(\"t1\", \"t0\", \"date\", \"Date\"),\n",
    "):\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    markets_str = \"-\".join(markets)\n",
    "\n",
    "    rows_pred = []\n",
    "    rows_true = []\n",
    "\n",
    "    def get_window_date(w):\n",
    "        for k in date_key_candidates:\n",
    "            if k in w:\n",
    "                d = pd.to_datetime(w[k])\n",
    "                return d\n",
    "        return None  # if no date info\n",
    "\n",
    "    # find first index in 2025 (so we \"start walking forward on 2025\")\n",
    "    first_2025_idx = None\n",
    "    for i in range(len(rolling)):\n",
    "        d = get_window_date(rolling[i])\n",
    "        if isinstance(d, pd.Timestamp) and d.year == year:\n",
    "            first_2025_idx = i\n",
    "            break\n",
    "\n",
    "    if first_2025_idx is None:\n",
    "        raise ValueError(f\"No windows found with year={year}. Check your rolling windows date keys.\")\n",
    "\n",
    "    # walk-forward loop: start at first 2025 window, but still need train_len history\n",
    "    start_i = max(train_len, first_2025_idx)\n",
    "    print(\"START i \")\n",
    "    print(first_2025_idx)\n",
    "    print(start_i)\n",
    "    print(len(rolling))\n",
    "    for i in range(start_i, len(rolling)):\n",
    "        train_windows = rolling[i-train_len:i]\n",
    "        test_window   = rolling[i]\n",
    "\n",
    "        period = get_window_date(test_window)\n",
    "        if isinstance(period, pd.Timestamp):\n",
    "            # if period.year != year: ## 2025\n",
    "            if period.year != year and period.year != year + 1: ## 2024-2025 !\n",
    "                continue\n",
    "        else:\n",
    "            # if no dates, we cannot filter by year; safest is to skip\n",
    "            continue\n",
    "\n",
    "        # --- build train panel ---\n",
    "        X_train, y_train, _ = panel_from_windows(train_windows, x_key=x_key, y_key=y_key)\n",
    "        if X_train.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # --- scaler on TRAIN only ---\n",
    "        scaler = StandardScaler()\n",
    "        X_train_sc = scaler.fit_transform(X_train).astype(np.float32)\n",
    "\n",
    "        # --- build test cross-section ---\n",
    "        X_test_df = test_window[x_key].T  # assets x features\n",
    "        y_test = test_window[y_key]\n",
    "        if not isinstance(y_test, pd.Series):\n",
    "            y_test = pd.Series(y_test, index=X_test_df.index)\n",
    "\n",
    "        assets = X_test_df.index.intersection(y_test.index).sort_values()\n",
    "        if len(assets) == 0:\n",
    "            continue\n",
    "\n",
    "        X_test = X_test_df.loc[assets].to_numpy(np.float32)\n",
    "        y_true = y_test.loc[assets].to_numpy(np.float32)\n",
    "\n",
    "        mask = np.isfinite(X_test).all(axis=1) & np.isfinite(y_true)\n",
    "        assets = assets[mask]\n",
    "        X_test = X_test[mask]\n",
    "        y_true = y_true[mask]\n",
    "\n",
    "        if len(assets) == 0:\n",
    "            continue\n",
    "\n",
    "        X_test_sc = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "        # --- train model (fresh each step) ---\n",
    "        keras.backend.clear_session()\n",
    "        model = build_mlp(in_dim=X_train_sc.shape[1], hidden=hidden, dropout=dropout, lr=lr)\n",
    "\n",
    "        # (optional) early stopping; monitor val_loss only if you pass validation_data\n",
    "        es = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=15, restore_best_weights=True)\n",
    "\n",
    "        model.fit(\n",
    "            X_train_sc, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0,\n",
    "            callbacks=[es]\n",
    "        )\n",
    "\n",
    "        # --- predict ---\n",
    "        y_pred = model.predict(X_test_sc, batch_size=1024, verbose=0).squeeze()\n",
    "\n",
    "        # store long rows (period, asset)\n",
    "        for a, yt, yp in zip(assets, y_true, y_pred):\n",
    "            rows_true.append({\"period\": period, \"asset\": a, \"true\": float(yt)})\n",
    "            rows_pred.append({\"period\": period, \"asset\": a, \"pred\": float(yp)})\n",
    "\n",
    "    # --- long -> wide ---\n",
    "    pred_long = pd.DataFrame(rows_pred)\n",
    "    true_long = pd.DataFrame(rows_true)\n",
    "\n",
    "    if pred_long.empty:\n",
    "        raise ValueError(\"No predictions were produced. Check train_len, date keys, or rolling coverage.\")\n",
    "\n",
    "    expected_df = pred_long.pivot(index=\"period\", columns=\"asset\", values=\"pred\").sort_index()\n",
    "    true_df     = true_long.pivot(index=\"period\", columns=\"asset\", values=\"true\").sort_index()\n",
    "\n",
    "    # align columns (union) so shapes match\n",
    "    all_cols = expected_df.columns.union(true_df.columns)\n",
    "    expected_df = expected_df.reindex(columns=all_cols)\n",
    "    true_df     = true_df.reindex(columns=all_cols)\n",
    "\n",
    "    errors_df = true_df - expected_df  # error = true - pred\n",
    "\n",
    "    # --- save ---\n",
    "    p_exp = os.path.join(out_dir, f\"{model_name}_{markets_str}_expected_returns.csv\")\n",
    "    p_true = os.path.join(out_dir, f\"{model_name}_{markets_str}_true_returns.csv\")\n",
    "    p_err = os.path.join(out_dir, f\"{model_name}_{markets_str}_errors.csv\")\n",
    "\n",
    "    expected_df.to_csv(p_exp)\n",
    "    true_df.to_csv(p_true)\n",
    "    errors_df.to_csv(p_err)\n",
    "\n",
    "    print(\"Saved:\")\n",
    "    print(\" \", p_exp, expected_df.shape)\n",
    "    print(\" \", p_true, true_df.shape)\n",
    "    print(\" \", p_err, errors_df.shape)\n",
    "\n",
    "    return expected_df, true_df, errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2048a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected_2025, true_2025, errors_2025 = walk_forward_export_mlp(\n",
    "#     rolling=rolling,\n",
    "#     markets=markets,     \n",
    "#     model_name=\"MLP\",\n",
    "#     year=2025,\n",
    "#     train_len=200,\n",
    "#     x_key=\"past_weekly_returns\",\n",
    "#     y_key=\"y_ret\",\n",
    "#     hidden=(32, 16),\n",
    "#     dropout=0.1,\n",
    "#     lr=1e-4,\n",
    "#     epochs=150,\n",
    "#     batch_size=256,\n",
    "#     out_dir=\"data/prediction\",\n",
    "#     date_key_candidates=('t1' , \"date\", \"Date\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea1254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START i \n",
      "190\n",
      "190\n",
      "430\n",
      "Saved:\n",
      "  data/prediction/MLP_dow30-commodities-bonds_expected_returns.csv (240, 40)\n",
      "  data/prediction/MLP_dow30-commodities-bonds_true_returns.csv (240, 40)\n",
      "  data/prediction/MLP_dow30-commodities-bonds_errors.csv (240, 40)\n"
     ]
    }
   ],
   "source": [
    "expected_2025, true_2025, errors_2025 = walk_forward_export_mlp(\n",
    "    rolling=rolling,\n",
    "    markets=markets,     \n",
    "    model_name=\"MLP\",\n",
    "    year=2024,\n",
    "    train_len=150,\n",
    "    x_key=\"past_weekly_returns\",\n",
    "    y_key=\"y_ret\",\n",
    "    hidden=(32, 16),\n",
    "    dropout=0.1,\n",
    "    lr=1e-4,\n",
    "    epochs=150,\n",
    "    batch_size=256,\n",
    "    out_dir=\"data/prediction\",\n",
    "    date_key_candidates=('t1' , \"date\", \"Date\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
